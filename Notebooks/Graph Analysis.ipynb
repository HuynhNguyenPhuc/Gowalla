{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0f5b193-85ab-4ada-ad6e-2c45f5af897a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9869fb27-0b0f-40e7-be26-11ef1340507e",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting graphframes\n",
       "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
       "Requirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from graphframes) (1.20.1)\n",
       "Collecting nose\n",
       "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
       "Installing collected packages: nose, graphframes\n",
       "Successfully installed graphframes-0.6 nose-1.3.7\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting graphframes\n  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from graphframes) (1.20.1)\nCollecting nose\n  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\nInstalling collected packages: nose, graphframes\nSuccessfully installed graphframes-0.6 nose-1.3.7\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb3e44c-aa34-4810-b843-cef21151f568",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n",
    "from operator import add\n",
    "import numpy as np\n",
    "\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26a8ab21-52d9-4025-b2e3-342dcc06b0e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81ee87bb-af9e-4188-bbdf-03a65122f301",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadGraph():\n",
    "    vertices = spark.sql(\"SELECT * FROM databricks_tourism_workspace.default.graph_vertices\")\n",
    "    edges = spark.sql(\"SELECT * FROM databricks_tourism_workspace.default.graph_edges\")\n",
    "    return vertices, edges\n",
    "\n",
    "def saveGraph(vertices, edges):\n",
    "    vertices.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"graph_vertices\")\n",
    "    edges.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"graph_edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3048bdbb-a782-4bdc-93fb-c6ea5db713f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08f332c5-44b7-4629-988d-5aa1d4d46790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM databricks_tourism_workspace.default.gowalla_checkins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727bb751-5448-49bc-a6d2-8de7877a486e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window = Window.orderBy(\"cluster\")\n",
    "\n",
    "df = df.withColumn(\"cluster\", F.dense_rank().over(window))\n",
    "df = df.withColumn(\"cluster\", F.col(\"cluster\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4ee581-38f1-48dd-bc86-20a5f523ff96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"databricks_tourism_workspace.default.gowalla_checkins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a956fc48-8d43-47db-82c9-f228e74b3b2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Graph Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb7d667a-f414-4f59-b511-c9b7b6287e96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getTourist(df):\n",
    "    window_spec = Window.partitionBy(\"user\").orderBy(\"checkinTime\")\n",
    "\n",
    "    # Add lag features\n",
    "    df_sample = df.withColumn(\"prevTimestamp\", F.lag(F.col(\"checkinTime\")).over(window_spec))\n",
    "\n",
    "    # Calculate time difference\n",
    "    df_sample = df_sample.withColumn(\"timeDiff\", F.unix_timestamp(F.col(\"checkinTime\")) - F.unix_timestamp(F.col(\"prevTimestamp\")))\n",
    "    \n",
    "    # Create a macro to identify each instance where the difference between two dates is larger than three days\n",
    "    df_sample = df_sample.withColumn(\"newSegment\", F.when(F.col(\"timeDiff\") > (3 * 24 * 60 * 60), 1).otherwise(0))\n",
    "    \n",
    "    # Add a column to calculate the cumulative sum of the newSegment column\n",
    "    df_sample = df_sample.withColumn(\"segment\", F.sum(\"newSegment\").over(window_spec))\n",
    "\n",
    "    tourists = df_sample.groupBy(\"user\", \"segment\").agg(F.collect_list(F.struct(\"cluster\", \"latitude\", \"longitude\", \"checkinTime\")).alias(\"tourists\"))\n",
    "    tourists = tourists.groupBy(\"user\").agg(F.collect_list(\"tourists\").alias(\"tourists\"))\n",
    "\n",
    "    return tourists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d20dcea-7ac7-4865-af95-4f3bc0f5d515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get tourist dataset\n",
    "tourists = getTourist(df)\n",
    "tourists.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"gowalla_tourist\")\n",
    "\n",
    "tourists = tourists.select(\"user\", F.explode(\"tourists\").alias(\"tourist\"))\n",
    "tourists = tourists.withColumn(\"index\", F.monotonically_increasing_id())\n",
    "tourists = tourists.select(\"user\", \"index\", F.explode(\"tourist\").alias(\"checkin\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"user\", \"index\").orderBy(\"checkin\")\n",
    "tourists = tourists.withColumn(\"prevCheckin\", F.lag(F.col(\"checkin\")).over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d6bb42-3ec9-4552-901b-5408b669ac67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edges = tourists.select(\n",
    "    F.col(\"prevCheckin.cluster\").alias(\"src\"),\n",
    "    F.col(\"checkin.cluster\").alias(\"dst\")\n",
    ").where(F.col(\"src\").isNotNull() & F.col(\"dst\").isNotNull())\n",
    "\n",
    "edges = edges.where(F.col(\"src\") != F.col(\"dst\"))\n",
    "edges = edges.groupBy(\"src\", \"dst\").agg(F.count(\"*\").alias(\"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc295d44-2d38-4df4-945c-e2e46f9ee9a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "incoming_weights = edges.groupBy(\"dst\").agg(F.sum(\"normal\").alias(\"incoming_weight\"))\n",
    "outgoing_weights = edges.groupBy(\"src\").agg(F.sum(\"normal\").alias(\"outgoing_weight\"))\n",
    "\n",
    "vertices = incoming_weights.join(outgoing_weights, incoming_weights.dst == outgoing_weights.src, how=\"full_outer\") \\\n",
    "    .select(F.coalesce(incoming_weights.dst, outgoing_weights.src).alias(\"id\"),\n",
    "            (F.coalesce(incoming_weights.incoming_weight, F.lit(0)) + F.coalesce(outgoing_weights.outgoing_weight, F.lit(0))).alias(\"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662255fc-1e3a-4331-b3a0-8a45e8a6e0a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "location_graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ae0199-dedb-479b-b64a-b6208b3bf8ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Graph Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac0952ec-ee7a-4ccd-9cbe-5a9d5a88e7df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2f1866e-b528-434c-9e26-9efa4f555dc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pagerank_results = location_graph.pageRank(resetProbability=0.15, tol = 1e-5)\n",
    "\n",
    "pagerank_results.vertices.withColumnRenamed(\"weight\", \"pagerank\").write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"graph_vertices\")\n",
    "pagerank_results.edges.withColumnRenamed(\"weight\", \"pagerank\").write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"graph_edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c503f1b6-7bbc-43de-b66e-ff475790044b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Number of points in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e875e1b-f6ba-48b9-9eb3-610dfeac2289",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusters = df.groupBy(\"cluster\").agg(F.count(\"*\").cast(\"int\").alias(\"num_points\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf02ed3b-6986-42fd-b863-a48e1d622a28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vertices, edges = loadGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2eea15-e4b9-4d86-9997-1925996500a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusters.createOrReplaceTempView(\"clusters\")\n",
    "vertices.createOrReplaceTempView(\"vertices\")\n",
    "\n",
    "vertices = spark.sql(\"\"\"\n",
    "    SELECT id, c.num_points, normal, pagerank\n",
    "    FROM vertices v JOIN clusters c ON v.id = c.cluster\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31b760b6-86cc-4a01-ac6c-697c9d1a62f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveGraph(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a2ebdbd-edd1-4966-a18e-513b405b7e3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Label Propagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b85601ba-27bf-4acb-ad2e-6a4562ff8c40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vertices, edges = loadGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d518fef-3510-4a9c-98dc-ccff4b76034c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "g = GraphFrame(vertices, edges)\n",
    "\n",
    "vertices = g.labelPropagation(maxIter=10)\n",
    "\n",
    "windowSpec = Window.orderBy(\"label\")\n",
    "vertices = vertices.withColumn(\"label\", F.dense_rank().over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbe2411c-3d26-4ec7-848b-8a87acaaf5d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "saveGraph(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8fbd0d6-9687-4441-82e6-0f72bc11b25e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Popular Tour Route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ec454a3-760a-410d-b154-5b80907eba80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transition Probabilty Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da6eb7f3-6176-4c38-9a2b-b4c648527ba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_weights = edges.groupBy(F.col(\"src\").alias(\"new_src\")).agg(F.sum(F.col(\"normal\")).alias(\"total_weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a700f33-486c-48c2-ad9f-c6af497b5db5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edges = edges.join(total_weights, edges.src == total_weights.new_src, \"left\"). \\\n",
    "        withColumn(\"transfer_prob\", F.col(\"normal\") / F.col(\"total_weights\")). \\\n",
    "        select(\"src\", \"dst\", \"transfer_prob\", \"normal\", \"pagerank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231d387d-c50e-489b-b139-903ceab61a7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "saveGraph(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bdb40c8-d612-4d18-8d86-55569e1c0e95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Markov Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a222b1c9-8022-4821-90bb-073d4517f5f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vertices, edges = loadGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2520b621-5de0-420c-9a01-4e40579a9341",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vertices_test = vertices.filter(F.col(\"id\") < 1000)\n",
    "edges_test = edges.filter((F.col(\"src\") < 1000) & (F.col(\"dst\") < 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eb2fd21-3e54-453a-a162-55825749976d",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Performs matrix multiplication of two CoordinateMatrices.\n",
    "    \n",
    "    Args:\n",
    "    A (CoordinateMatrix): First matrix.\n",
    "    B (CoordinateMatrix): Second matrix.\n",
    "    \n",
    "    Returns:\n",
    "    CoordinateMatrix: Resultant matrix after multiplication.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        A_rdd = A.entries.map(lambda x: (x.j,(x.i,x.value))) \n",
    "        B_rdd = B.entries.map(lambda x: (x.i,(x.j,x.value))) \n",
    "        interm_rdd = A_rdd.join(B_rdd).map(lambda x: ((x[1][0][0],x[1][1][0]),(x[1][0][1]*x[1][1][1])))\n",
    "        C_rdd = interm_rdd.reduceByKey(add).map(lambda x: MatrixEntry(x[0][0],x[0][1],x[1])) \n",
    "        return CoordinateMatrix(C_rdd)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in matrix multiplication: {str(e)}\")\n",
    "\n",
    "def matrix_multiply_mod(a, b):\n",
    "    \"\"\"\n",
    "    Performs matrix multiplication in BlockMatrix style.\n",
    "    \n",
    "    Args:\n",
    "    a (CoordinateMatrix): First matrix.\n",
    "    b (CoordinateMatrix): Second matrix.\n",
    "    \n",
    "    Returns:\n",
    "    CoordinateMatrix: Resultant matrix after multiplication.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bmat_a = a.toBlockMatrix()\n",
    "        b_tanspose= b.transpose()\n",
    "        bmat_b_tanspose=b_tanspose.toBlockMatrix()\n",
    "        bmat_result= bmat_a.multiply(bmat_b_tanspose)\n",
    "        return bmat_result.toCoordinateMatrix()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in modified matrix multiplication: {str(e)}\")\n",
    "\n",
    "def normalize_mat(df):\n",
    "    \"\"\"\n",
    "    Normalize the matrix by calculating L1 norm.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): DataFrame representing the coordinate matrix.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame of normalized matrix.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = df.columns\n",
    "        df = df.withColumnRenamed(cols[0],'src').withColumnRenamed(cols[1],'dest').withColumnRenamed(cols[2],'wt')\n",
    "        tdf = df.groupby('dest').agg({'wt':'sum'}).withColumnRenamed('dest','dest_t').withColumnRenamed('sum(wt)','total_t')\n",
    "        df = df.join(tdf,df.dest==tdf.dest_t)\n",
    "        df = df.withColumn('new_wts', F.col('wt').cast('float')/F.col('total_t'))\n",
    "        df = df.select('src','dest','new_wts')\n",
    "        df = df.withColumnRenamed('src',cols[0]).withColumnRenamed('dest',cols[1]).withColumnRenamed('new_wts',cols[2])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in matrix normalization: {str(e)}\")\n",
    "\n",
    "def expand_mat(df,power,blockstyle=True):\n",
    "    \"\"\"\n",
    "    Calculate the nth power of a matrix A.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): DataFrame of the coordinate matrix A.\n",
    "    power (int): Exponent to which the matrix should be raised.\n",
    "    blockstyle (bool): Calculate matrix multiplication block style or by simple RDD joins.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame of A^n matrix with source, destination, and weight columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = df.columns\n",
    "        cdf =  CoordinateMatrix(df.rdd.map(tuple))\n",
    "        rdf = cdf\n",
    "        if blockstyle:\n",
    "            for i in range(power-1):\n",
    "                rdf = matrix_multiply_mod(rdf,cdf)\n",
    "        else:\n",
    "            for i in range(power-1):\n",
    "                rdf = matrix_multiply(rdf,cdf)\n",
    "        rdf_rdd = rdf.entries.map(lambda x: (x.i,x.j,x.value))\n",
    "        result_df = rdf_rdd.toDF()\n",
    "        result_df = result_df.withColumnRenamed('_1',cols[0]).withColumnRenamed('_2',cols[1]).withColumnRenamed('_3',cols[2])\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in matrix expansion: {str(e)}\")\n",
    "\n",
    "def inflate_mat(df,inflate_size):\n",
    "    \"\"\"\n",
    "    Raise each element of the matrix to the given power.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): DataFrame of the coordinate matrix.\n",
    "    inflate_size (int or float): Power to which each element should be raised.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame of inflated matrix with source, destination, and weight columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = df.columns\n",
    "        df = df.withColumnRenamed(cols[0],'src').withColumnRenamed(cols[1],'dest').withColumnRenamed(cols[2],'wt')\n",
    "        df = df.withColumn('new_wts', F.col('wt')**inflate_size)\n",
    "        df = df.select('src','dest','new_wts')\n",
    "        df = df.withColumnRenamed('src',cols[0]).withColumnRenamed('dest',cols[1]).withColumnRenamed('new_wts',cols[2])\n",
    "        df = normalize_mat(df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in matrix inflation: {str(e)}\")\n",
    "\n",
    "def prune_mat(df,threshold):\n",
    "    \"\"\"\n",
    "    Prune the matrix if the weights are below a certain threshold.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): DataFrame of the coordinate matrix.\n",
    "    threshold (float): Threshold below which weights are ignored.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Pruned DataFrame with source, destination, and weight columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = df.columns\n",
    "        df = df.filter(F.col(cols[2])>threshold)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in matrix pruning: {str(e)}\")\n",
    "\n",
    "def converged(df1,df2):\n",
    "    \"\"\"\n",
    "    Check for convergence by calculating the difference between the weights.\n",
    "    \n",
    "    Args:\n",
    "    df1 (DataFrame): DataFrame of the coordinate matrix 1.\n",
    "    df2 (DataFrame): DataFrame of the coordinate matrix 2.\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if matrices are converged, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols1 = df1.columns\n",
    "        cols2 = df2.columns\n",
    "        df1 = df1.withColumnRenamed(cols1[0],'src1').withColumnRenamed(cols1[1],'dest1').withColumnRenamed(cols1[2],'wt1').persist()\n",
    "        df2 = df2.withColumnRenamed(cols2[0],'src2').withColumnRenamed(cols2[1],'dest2').withColumnRenamed(cols2[2],'wt2').persist()\n",
    "        df1.count()\n",
    "        df2.count()\n",
    "\n",
    "        @udf('int')\n",
    "        def np_allclose(a,b):\n",
    "            return int(np.allclose(a, b))\n",
    "\n",
    "        df = df2.join(df1,(df1.src1==df2.src2) & (df1.dest1==df2.dest2), 'left').persist()\n",
    "        df.count()\n",
    "        df = df.fillna({'wt1':0})\n",
    "        df = df.withColumn('allclose',np_allclose(F.col('wt1'),F.col('wt2'))).persist()\n",
    "\n",
    "        if df.count() == df.filter(df.allclose==1).count():\n",
    "            df.unpersist()\n",
    "            return True\n",
    "        else:\n",
    "            df.unpersist()\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in convergence check: {str(e)}\")\n",
    "\n",
    "def get_clusters(df):\n",
    "    \"\"\"\n",
    "    Fetch clusters from the converged matrix.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): DataFrame of the coordinate matrix.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame of the clusters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = df.columns\n",
    "        df = df.withColumnRenamed(cols[0],'src').withColumnRenamed(cols[1],'dest').withColumnRenamed(cols[2],'wt')\n",
    "        diagonals = df.filter((df.src==df.dest)&(df.wt>0)).select('src').distinct().collect()\n",
    "        ids = [r[0] for r in diagonals]\n",
    "        fdf = df.filter(df.src.isin(ids)).groupby('src').agg(F.collect_list('dest').alias(\"value\"))\n",
    "        fdf = fdf.rdd.zipWithIndex().toDF().withColumnRenamed('_1','nodes').withColumnRenamed('_2','cluster')\n",
    "        fdf = fdf.select('cluster','nodes')\n",
    "        return fdf\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in cluster extraction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d57a1c-9681-4e09-8e1e-425c7b73e0de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def runScaledMCL(matrix, expansion=2, inflation=2, loop_value=1, iterations=100, pruning_threshold=0.001, pruning_frequency=1, convergence_check_frequency=1):\n",
    "    \"\"\"\n",
    "    Run the scaled Markov Clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "    matrix (DataFrame): Input DataFrame.\n",
    "    expansion (int): Expansion rate.\n",
    "    inflation (int): Inflation rate.\n",
    "    loop_value (int): Value for self-loops.\n",
    "    iterations (int): Number of iterations.\n",
    "    pruning_threshold (float): Pruning threshold.\n",
    "    pruning_frequency (int): Pruning frequency.\n",
    "    convergence_check_frequency (int): Convergence check frequency.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Result of the MCL algorithm.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize variables\n",
    "        result_matrix = None\n",
    "\n",
    "        # Iterate through the specified number of iterations\n",
    "        for i in range(iterations):\n",
    "            # Perform MCL steps\n",
    "            # Step 1: Expansion\n",
    "            expanded_matrix = expand_mat(matrix, expansion)\n",
    "\n",
    "            # Step 2: Inflation\n",
    "            inflated_matrix = inflate_mat(expanded_matrix, inflation)\n",
    "\n",
    "            # Step 3: Pruning\n",
    "            pruned_matrix = prune_mat(inflated_matrix, pruning_threshold)\n",
    "\n",
    "            # Check for convergence\n",
    "            if i % convergence_check_frequency == 0:\n",
    "                if converged(matrix, pruned_matrix):\n",
    "                    logging.info(f\"MCL algorithm converged after {i} iterations.\")\n",
    "                    break\n",
    "\n",
    "            # Update the matrix for the next iteration\n",
    "            matrix = pruned_matrix\n",
    "\n",
    "        # Extract clusters from the converged matrix\n",
    "        clusters_df = get_clusters(pruned_matrix)\n",
    "\n",
    "        return clusters_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in MCL algorithm: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb23ebb4-21cd-45d7-887a-c84195507b8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = runScaledMCL(matrix = edges_test.select(\"src\", \"dst\", \"normal\"), iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5a6ff9-5e15-4797-bb3a-cb6ca1e55ffc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"gowalla_mcl\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Graph Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
